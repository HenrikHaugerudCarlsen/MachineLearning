{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "#from matplotlib.ticker import LinearLocator, FormatStrFormatter,\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import autograd.numpy as np\n",
    "from autograd import grad, elementwise_grad,jacobian, hessian\n",
    "import pandas as pd\n",
    "from random import random, seed\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "plt.rcParams['font.size'] = 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(y):\n",
    "    return np.exp(y)/(1+np.exp(y))\n",
    "def Identity(y):\n",
    "    return y\n",
    "\n",
    "def RELU(y):\n",
    "    return np.maximum(0,y)\n",
    "\n",
    "def lexyRelu(y):\n",
    "    return np.maximum(0.01*y,y)\n",
    "\n",
    "def Set_weights_and_bias(n_in,n_hidden,n_out):\n",
    "#### Setting hiden weights\n",
    "    W_hidden = np.random.randn(n_in, n_hidden)\n",
    "    b_hidden = np.zeros(n_hidden) +0.01\n",
    "#### setting output weights\n",
    "    W_out = np.random.randn(n_hidden, n_out)\n",
    "    b_out = np.zeros(n_out) +0.01\n",
    "    return W_hidden, W_out, b_hidden, b_out\n",
    "\n",
    "#### From lecture notes\n",
    "def feed_forward_train(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function):\n",
    "#### Hidden attac\n",
    "    z_h = X@W_hidden + b_hidden\n",
    "    a_h = activation_function(z_h)\n",
    "#### output attac\n",
    "    z_o = a_h@W_out + b_out\n",
    "    a_o = output_function(z_o)\n",
    "    return a_h, a_o, z_h,z_o\n",
    "\n",
    "\n",
    "def feed_forward(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function):\n",
    "#### Hidden attac\n",
    "    z_h = X@W_hidden + b_hidden\n",
    "    a_h = activation_function(z_h)\n",
    "#### output attac\n",
    "    z_o = a_h@W_out + b_out\n",
    "    a_o = output_function(z_o)\n",
    "    return a_o[0]\n",
    "\n",
    "def u(x):\n",
    "    return np.sin(np.pi*x)\n",
    "\n",
    "def g_trial(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function):\n",
    "    x,t = X[0],X[1]\n",
    "    return (1-t)*u(x) + x*(1-x)*t*feed_forward(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "\n",
    "#### From notes\n",
    "def cost_function(x,t,W_hidden, W_out, b_hidden, b_out,activation_function, output_function):\n",
    "    cost_sum = 0\n",
    "    \n",
    "    g_t_jac_fun = jacobian(g_trial)\n",
    "    g_t_hessian_fun = hessian(g_trial)\n",
    "    \n",
    "    for x_ in x:\n",
    "        for t_ in t:\n",
    "            X = np.array([x_,t_])\n",
    "            g_t = g_trial(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            g_t_jac = g_t_jac_fun(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            g_t_hessian =g_t_hessian_fun(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "           # print(g_t)\n",
    "            g_t_dt = g_t_jac[1]\n",
    "            g_t_d2x = g_t_hessian[0][0]\n",
    "            \n",
    "            error = g_t_dt -g_t_d2x\n",
    "            cost_sum += error**2\n",
    "    return cost_sum/(np.size(x)*np.size(t))\n",
    "\n",
    "### from notes, altered to fitt our setup\n",
    "def solution(x,t,N_hidden,eta, activation_function ,output_function, epoch,Minibach):\n",
    "    W_hidden, W_out, b_hidden, b_out = Set_weights_and_bias(2,N_hidden,1)\n",
    " #   print('Initial cost: ', cost_function(x,t,W_hidden, W_out, b_hidden, b_out,activation_function, output_function))\n",
    "    \n",
    "    cost_func_wh_grad = elementwise_grad(cost_function,2)\n",
    "    cost_func_bh_grad = elementwise_grad(cost_function,4)\n",
    "    cost_func_wo_grad = elementwise_grad(cost_function,3)\n",
    "    cost_func_bo_grad = elementwise_grad(cost_function,5)\n",
    "    MiniBachSize =int(np.size(x)/Minibach)\n",
    "    for e in range(epoch):\n",
    "        for j in range(Minibach):\n",
    "            miniBach = np.random.randint(Minibach)\n",
    "            miniBachMin, miniBachMax = MiniBachSize * miniBach,(MiniBachSize) * (miniBach+1)\n",
    "            x_bach,t_bach = x[miniBachMin:miniBachMax],t[miniBachMin:miniBachMax]\n",
    "            W_hidden -= eta*cost_func_wh_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            W_out -= eta*cost_func_wo_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            b_hidden -= eta*cost_func_bh_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            b_out -= eta*cost_func_bo_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "      #  print(\"finished iteration number: \", e)\n",
    "   \n",
    "   # print('Final cost: ', cost_function(x,t,W_hidden, W_out, b_hidden, b_out,activation_function, output_function))\n",
    "    return W_hidden, W_out, b_hidden, b_out\n",
    "\n",
    "#### This one is nice when we want to study how the MSE converges\n",
    "def Solution2(x,t,N_hidden,eta, epoch,Minibach, W_hidden, W_out, b_hidden, b_out):\n",
    "    cost_func_wh_grad = elementwise_grad(cost_function,2)\n",
    "    cost_func_bh_grad = elementwise_grad(cost_function,4)\n",
    "    cost_func_wo_grad = elementwise_grad(cost_function,3)\n",
    "    cost_func_bo_grad = elementwise_grad(cost_function,5)\n",
    "    activation_function = Sigmoid\n",
    "    output_function = Identity\n",
    "    MiniBachSize =int(np.size(x)/Minibach)\n",
    "    for e in range(epoch):\n",
    "        for j in range(Minibach):\n",
    "            miniBach = np.random.randint(Minibach)\n",
    "            miniBachMin, miniBachMax = MiniBachSize * miniBach,(MiniBachSize) * (miniBach+1)\n",
    "            x_bach,t_bach = x[miniBachMin:miniBachMax],t[miniBachMin:miniBachMax]\n",
    "            W_hidden -= eta*cost_func_wh_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            W_out -= eta*cost_func_wo_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            b_hidden -= eta*cost_func_bh_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "            b_out -= eta*cost_func_bo_grad(x_bach,t_bach,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "      #  print(\"finished iteration number: \", e)\n",
    "   \n",
    "   # print('Final cost: ', cost_function(x,t,W_hidden, W_out, b_hidden, b_out,activation_function, output_function))\n",
    "    return W_hidden, W_out, b_hidden, b_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing the strap:)\n"
     ]
    }
   ],
   "source": [
    "##### We have changed how we test and train. The train is done on a random unsorted grid, while the test is done on a fixed grid\n",
    "##### This square finds the \n",
    "x = np.random.uniform(0,1,6)\n",
    "t = np.random.uniform(0,1,6)\n",
    "\n",
    "t_test = np.linspace(0,1,50)\n",
    "x_test = np.linspace(0,1,50)\n",
    "\n",
    "etas = np.logspace(-4,1,4)\n",
    "\n",
    "\n",
    "activation_functions = [Sigmoid,RELU,lexyRelu,Identity]\n",
    "output_function = Identity\n",
    "epoch,Minibach = 100, 3\n",
    "N_hidden = 32\n",
    "N_straps = 10\n",
    "\n",
    "error_list = np.zeros((np.size(etas),np.size(activation_functions)))\n",
    "##### Training our network :)\n",
    "k,l= 0,0\n",
    "for eta in etas:\n",
    "    for activation_function in activation_functions:\n",
    "        g_error = 0\n",
    "        print(\"Doing the strap:)\")\n",
    "        for counter in range(N_straps):\n",
    "            W_hidden, W_out, b_hidden, b_out = solution(x,t,N_hidden,eta, activation_function ,output_function, epoch,Minibach)\n",
    "            error = 0\n",
    "            u_t = np.zeros((50,50))\n",
    "            i,j= 0,0\n",
    "            for x_0 in x_test:\n",
    "                for t_0 in t_test:\n",
    "                    X_0 = np.array([x_0,t_0])\n",
    "                    u_t[j,i] = g_trial(X_0,W_hidden, W_out, b_hidden, b_out,Sigmoid, Identity)\n",
    "                    error += (u_t[j,i]-u(x_0)*np.exp(-np.pi**2*t_0))**2\n",
    "                    j+=1\n",
    "                j=0\n",
    "                i+=1\n",
    "   #         plt.imshow(u_t,origin='lower')\n",
    "   #         plt.show()\n",
    "            error/= (np.size(t_test)*np.size(x_test))\n",
    "            g_error += error\n",
    "           # print(error)\n",
    "        g_error /= N_straps\n",
    "        error_list[k,l] += g_error\n",
    "        l+=1\n",
    "    k+=1\n",
    "    l= 0 \n",
    "\n",
    "tick = ticker.ScalarFormatter(useOffset=False, useMathText=True)\n",
    "tick.set_powerlimits((0,0))\n",
    "\n",
    "tx = [u\"${}$\".format(tick.format_data(x)) for x in [1,2,3,4]]\n",
    "ty = [u\"${}$\".format(tick.format_data(x)) for x in etas]\n",
    "\n",
    "#lambdas_sea = [lambdas[i] for i in range(len(lambdas))]\n",
    "#etas_sea =  [etas[i] for i in range(len(etas))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(data=error_list,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\n",
    "ax.set_xlabel(r'Activation Function')\n",
    "ax.set_ylabel(r'$\\eta$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Test_Accuracy_Single_hidden_layer.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution as function of epochs\n",
    "x = np.random.uniform(0,1,10)\n",
    "t = np.random.uniform(0,1,10)\n",
    "\n",
    "t_test = np.linspace(0,1,50)\n",
    "x_test = np.linspace(0,1,50)\n",
    "\n",
    "N_hidden = 32\n",
    "eta = 0.01\n",
    "epoch = 10\n",
    "Minibach = 5\n",
    "\n",
    "epoch_List = np.linspace(10,1000,100)\n",
    "error_list = np.zeros_like(epoch_List)\n",
    "\n",
    "W_hidden, W_out, b_hidden, b_out = Set_weights_and_bias(2,N_hidden,1)\n",
    "for i in range(100):\n",
    "    W_hidden, W_out, b_hidden, b_out = Solution2(x,t,N_hidden,eta, epoch,Minibach, W_hidden, W_out, b_hidden, b_out)\n",
    "    error = 0\n",
    "    u_t = np.zeros((50,50))\n",
    "    l,j= 0,0\n",
    "    for x_0 in x_test:\n",
    "        for t_0 in t_test:\n",
    "            X_0 = np.array([x_0,t_0])\n",
    "            u_t[j,l] = g_trial(X_0,W_hidden, W_out, b_hidden, b_out,Sigmoid, Identity)\n",
    "            error += (u_t[j,l]-u(x_0)*np.exp(-np.pi**2*t_0))**2\n",
    "            j+=1\n",
    "        j=0\n",
    "        l+=1\n",
    "#         plt.imshow(u_t,origin='lower')\n",
    "#         plt.show()\n",
    "    error/= (np.size(t_test)*np.size(x_test))\n",
    "    error_list[i] = error\n",
    "    print(i)\n",
    "    \n",
    "plt.plot(epoch_List,error_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.tight_layout()\n",
    "plt.savefig('MSE as a fucntin of epochs.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x_test, u_t[0,:],label=r'$t=0$')\n",
    "plt.plot(x_test, u_t[9,:],label= r'$t=$' + str(t_test[9]))\n",
    "plt.plot(x_test, u_t[19,:],label= r'$t=$' + str(t_test[19]))\n",
    "plt.plot(x_test, u_t[29,:],label= r'$t=$' + str(t_test[29]))\n",
    "plt.plot(x_test, u_t[39,:],label= r'$t=$' + str(t_test[39]))\n",
    "plt.plot(x_test, u_t[49,:],label= r'$t=$' + str(t_test[49]))\n",
    "plt.legend()\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
