{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "#from matplotlib.ticker import LinearLocator, FormatStrFormatter,\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import autograd.numpy as np\n",
    "from autograd import grad, elementwise_grad\n",
    "import pandas as pd\n",
    "from random import random, seed\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "plt.rcParams['font.size'] = 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnpoints =20\\nx = np.sort(np.random.uniform(0, 1, npoints)) \\ny = np.sort(np.random.uniform(0, 1, npoints)) \\nx, y = np.meshgrid(x,y)\\nX = create_X(x, y)\\n\\nY = FrankeFunction(x, y) \\n\\nX_train, X_test, y_train, y_test = train_test_split(X, Y.reshape(-1,1), test_size=0.2)\\n\\nnumberMinibach = np.array([4,8,16,32,64])\\nnumEpochs = np.array([10,100,1000])\\n#epoch_index, minibach_index = 0,3 \\netas = np.logspace(-3,-1,3)\\nlambdas = np.logspace(-4,0,5)\\nnumberOfStraps = 100\\nhyper_par = np.logspace(-6,-1,6) \\n#hyper = 0\\n\\nepochs = 100 #numEpochs[1]\\nMinibach = numberMinibach[1] \\n#n_hiden = np.array([1,2,4,8,16])\\nhiden = 8\\n\\nMSE_test_ler = np.zeros((len(etas),len(hyper_par)))\\nMSE_train_ler = np.zeros((len(etas),len(hyper_par)))\\nR2_test_ler = np.zeros((len(etas),len(hyper_par)))\\nR2_train_ler = np.zeros((len(etas),len(hyper_par)))\\ncounter_eta, counter_hidden =0,0\\nfor hyper in hyper_par:\\n    for eta in etas:\\n        MSEdeglisttest = np.zeros(numberOfStraps)\\n        MSEdeglisttrain = np.zeros(numberOfStraps)\\n        R2deglisttest = np.zeros(numberOfStraps)\\n        R2deglisttrain = np.zeros(numberOfStraps)\\n        for i in range(numberOfStraps):\\n            w_h,w_o,b_h,b_o =Set_weights_and_bias(2,hiden,1)\\n            bootX,booty = resample(X_train,y_train.reshape(-1,1))\\n            MiniBachSize = int(bootX.shape[0]/Minibach)\\n            for e in range(epochs):\\n                for j in range(Minibach):\\n                    miniBach = np.random.randint(Minibach)\\n                    miniBachMin, miniBachMax = MiniBachSize * miniBach,(MiniBachSize) * (miniBach+1)\\n                    #a_h,a_o = feed_forward_train(bootX[miniBachMin: miniBachMax],w_h,w_o,b_h,b_o,Sigmoid,Identity)\\n                    w_out_grad,w_hidden_grad,b_out_grad, b_hidden_grad = back_prop(\\n                        bootX[miniBachMin: miniBachMax],booty[miniBachMin: miniBachMax],w_h, w_o, b_h, b_o,lexyRelu, Identity,hyper,CostFunction)\\n                    w_h -= eta*w_hidden_grad\\n                    w_o -= eta*w_out_grad\\n                    b_h -= eta*b_hidden_grad\\n                    b_o -= eta*b_out_grad\\n            a_h, y_pred_test,z_h,z_o =feed_forward_train(X_test,w_h,w_o,b_h,b_o,lexyRelu,Identity)\\n            a_h, y_pred_train,z_h,z_o =feed_forward_train(X_train,w_h,w_o,b_h,b_o,lexyRelu,Identity)\\n            MSEdeglisttest[i] =MSE(y_test,y_pred_test)\\n            MSEdeglisttrain[i]= MSE(y_train,y_pred_train)\\n            R2deglisttest[i] = R2(y_test,y_pred_test)\\n            R2deglisttrain[i] = R2(y_train,y_pred_train)\\n        MSE_train_ler[counter_eta,counter_hidden] = np.mean(MSEdeglisttrain)\\n        MSE_test_ler[counter_eta,counter_hidden] = np.mean(MSEdeglisttest)\\n        R2_test_ler[counter_eta,counter_hidden] = np.mean(R2deglisttest)\\n        R2_train_ler[counter_eta,counter_hidden] = np.mean(R2deglisttrain)\\n        counter_eta +=1\\n        print(counter_eta)\\n    counter_hidden +=1\\n    counter_eta =0\\n\\ntick = ticker.ScalarFormatter(useOffset=False, useMathText=True)\\ntick.set_powerlimits((0,0))\\n\\ntx = [u\"${}$\".format(tick.format_data(x)) for x in hyper_par]\\nty = [u\"${}$\".format(tick.format_data(x)) for x in etas]\\n\\n#lambdas_sea = [lambdas[i] for i in range(len(lambdas))]\\n#etas_sea =  [etas[i] for i in range(len(etas))]\\n\\nfig, ax = plt.subplots(figsize = (10, 10))\\nsns.heatmap(data=MSE_test_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\\nax.set_xlabel(r\\'$\\\\lambda$\\')\\nax.set_ylabel(r\\'$\\\\eta$\\')\\nplt.tight_layout()\\nplt.savefig(f\"Test_MSE_Single_hidden_function_of_hyper_RELU.pdf\")\\nplt.show()\\n\\nfig, ax = plt.subplots(figsize = (10, 10))\\nsns.heatmap(data=R2_test_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\\nax.set_xlabel(r\\'$\\\\lambda$\\')\\nax.set_ylabel(r\\'$\\\\eta$\\')\\nplt.tight_layout()\\nplt.savefig(f\"Test_R2_Single_hidden_function_of_hyper_RELU.pdf\")\\nplt.show()\\n\\n\\nfig, ax = plt.subplots(figsize = (10, 10))\\nsns.heatmap(data=MSE_train_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\\nax.set_xlabel(r\\'$\\\\lambda$\\')\\nax.set_ylabel(r\\'$\\\\eta$\\')\\nplt.tight_layout()\\nplt.savefig(f\"Train_MSE_Single_hidden_function_of_hyper_RELU.pdf\")\\nplt.show()\\n\\nfig, ax = plt.subplots(figsize = (10, 10))\\nsns.heatmap(data=R2_train_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\\nax.set_xlabel(r\\'$\\\\lambda$\\')\\nax.set_ylabel(r\\'$\\\\eta$\\')\\nplt.tight_layout()\\nplt.savefig(f\"Train_R2_Single_hidden_function_of_hyper_RELU.pdf\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\n",
    "    return term1 + term2 + term3 + term4 \n",
    "\n",
    "# Creating the design matrix, from lecture notes\n",
    "def create_X(x, y):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = 2 # Number of elements in beta\n",
    "    X = np.ones((N,l))\n",
    "    X[:,0] = x\n",
    "    X[:,1] = y\n",
    "    return X\n",
    "\n",
    "\n",
    "# Defining the Mean square error, from lecture notes\n",
    "def CostFunction(y,ytilde):\n",
    "    n = len(y)\n",
    "    return 1/n * np.sum(np.abs(y-ytilde)**2)\n",
    "\n",
    "def CostFunctionClassification(ao,target):\n",
    "    n= len(ao)\n",
    "    return -1/n*np.sum(target*np.log(ao) + (1-target)*np.log(1-ao))\n",
    "    \n",
    "def DerCostFunctionClassification(ao,target):\n",
    "    n= len(ao)\n",
    "    return -1/n* (target/np.abs(ao) -(1-target)/np.abs(1-ao) )\n",
    "\n",
    "def MSE(y,ytilde):\n",
    "    n = len(y)\n",
    "    return 1/n * np.sum(np.abs(y-ytilde)**2)\n",
    "\n",
    "# Defining the R2 function, from lecture notes\n",
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "\n",
    "def DerivariveCostFunc(y,ytilde):\n",
    "    n = len(y)\n",
    "    return 2/n*(y-ytilde)\n",
    "\n",
    "def Sigmoid(y):\n",
    "    return np.exp(y)/(1+np.exp(y))\n",
    "\n",
    "def RELU(y):\n",
    "    return np.maximum(0,y)\n",
    "\n",
    "def lexyRelu(y):\n",
    "    return np.maximum(0.01*y,y)\n",
    "\n",
    "def Identity(y):\n",
    "    return y\n",
    "\n",
    "def Accuracy(ao,target):\n",
    "    n = len(target)\n",
    "    ao = np.rint(ao)\n",
    "    target = np.rint(target)\n",
    "    s =0\n",
    "    for i in range(n):\n",
    "        if ao[i]==target[i]:\n",
    "            s +=1\n",
    "    return s/n\n",
    "\n",
    "#### From lecture notes\n",
    "def Set_weights_and_bias(n_in,n_hidden,n_out):\n",
    "#### Setting hiden weights\n",
    "    W_hidden = 0.1*np.random.randn(n_in, n_hidden)\n",
    "    b_hidden = np.zeros(n_hidden) +0.01\n",
    "#### setting output weights\n",
    "    W_out = 0.1*np.random.randn(n_hidden, n_out)\n",
    "    b_out = np.zeros(n_out) +0.01\n",
    "    return W_hidden, W_out, b_hidden, b_out\n",
    "\n",
    "#### From lecture notes\n",
    "def feed_forward_train(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function):\n",
    "#### Hidden attac\n",
    "    z_h = X@W_hidden + b_hidden\n",
    "    a_h = activation_function(z_h)\n",
    "#### output attac\n",
    "    z_o = a_h@W_out + b_out\n",
    "    a_o = output_function(z_o)\n",
    "    return a_h, a_o, z_h,z_o\n",
    "\n",
    "#### from lecture notes\n",
    "def back_prop(X,Target,W_hidden, W_out, b_hidden, b_out,activation_function, output_function,hyper_par,cost_func):\n",
    "    a_h, a_o,z_h,z_o = feed_forward_train(X,W_hidden, W_out, b_hidden, b_out,activation_function, output_function)\n",
    "#### output error\n",
    "    #print(z_o.shape)\n",
    "    error_out = elementwise_grad(cost_func,0)(a_o,Target)*elementwise_grad(output_function,0)(z_o) #* derivative of output_function\n",
    "### hidden error\n",
    "    error_hiden = (error_out @ W_out.T)* elementwise_grad(activation_function,0)(z_h) #*  a_h * (1 - a_h) # the last two terms are the derivative of the sigmoid\n",
    "##### the last term is the term due to the hyperparameter\n",
    "    w_out_grad = a_h.T @ error_out + 2*hyper_par*W_out\n",
    "    b_out_grad = np.sum(error_out, axis=0)\n",
    "    \n",
    "    w_hidden_grad = X.T @error_hiden+ 2*hyper_par*W_hidden\n",
    "    b_hidden_grad = np.sum(error_hiden,axis=0)\n",
    "    \n",
    "    return w_out_grad,w_hidden_grad, b_out_grad, b_hidden_grad\n",
    "\n",
    "###### Main Regression #######\n",
    "\"\"\"\n",
    "npoints =20\n",
    "x = np.sort(np.random.uniform(0, 1, npoints)) \n",
    "y = np.sort(np.random.uniform(0, 1, npoints)) \n",
    "x, y = np.meshgrid(x,y)\n",
    "X = create_X(x, y)\n",
    "\n",
    "Y = FrankeFunction(x, y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y.reshape(-1,1), test_size=0.2)\n",
    "\n",
    "numberMinibach = np.array([4,8,16,32,64])\n",
    "numEpochs = np.array([10,100,1000])\n",
    "#epoch_index, minibach_index = 0,3 \n",
    "etas = np.logspace(-3,-1,3)\n",
    "lambdas = np.logspace(-4,0,5)\n",
    "numberOfStraps = 100\n",
    "hyper_par = np.logspace(-6,-1,6) \n",
    "#hyper = 0\n",
    "\n",
    "epochs = 100 #numEpochs[1]\n",
    "Minibach = numberMinibach[1] \n",
    "#n_hiden = np.array([1,2,4,8,16])\n",
    "hiden = 8\n",
    "\n",
    "MSE_test_ler = np.zeros((len(etas),len(hyper_par)))\n",
    "MSE_train_ler = np.zeros((len(etas),len(hyper_par)))\n",
    "R2_test_ler = np.zeros((len(etas),len(hyper_par)))\n",
    "R2_train_ler = np.zeros((len(etas),len(hyper_par)))\n",
    "counter_eta, counter_hidden =0,0\n",
    "for hyper in hyper_par:\n",
    "    for eta in etas:\n",
    "        MSEdeglisttest = np.zeros(numberOfStraps)\n",
    "        MSEdeglisttrain = np.zeros(numberOfStraps)\n",
    "        R2deglisttest = np.zeros(numberOfStraps)\n",
    "        R2deglisttrain = np.zeros(numberOfStraps)\n",
    "        for i in range(numberOfStraps):\n",
    "            w_h,w_o,b_h,b_o =Set_weights_and_bias(2,hiden,1)\n",
    "            bootX,booty = resample(X_train,y_train.reshape(-1,1))\n",
    "            MiniBachSize = int(bootX.shape[0]/Minibach)\n",
    "            for e in range(epochs):\n",
    "                for j in range(Minibach):\n",
    "                    miniBach = np.random.randint(Minibach)\n",
    "                    miniBachMin, miniBachMax = MiniBachSize * miniBach,(MiniBachSize) * (miniBach+1)\n",
    "                    #a_h,a_o = feed_forward_train(bootX[miniBachMin: miniBachMax],w_h,w_o,b_h,b_o,Sigmoid,Identity)\n",
    "                    w_out_grad,w_hidden_grad,b_out_grad, b_hidden_grad = back_prop(\n",
    "                        bootX[miniBachMin: miniBachMax],booty[miniBachMin: miniBachMax],w_h, w_o, b_h, b_o,lexyRelu, Identity,hyper,CostFunction)\n",
    "                    w_h -= eta*w_hidden_grad\n",
    "                    w_o -= eta*w_out_grad\n",
    "                    b_h -= eta*b_hidden_grad\n",
    "                    b_o -= eta*b_out_grad\n",
    "            a_h, y_pred_test,z_h,z_o =feed_forward_train(X_test,w_h,w_o,b_h,b_o,lexyRelu,Identity)\n",
    "            a_h, y_pred_train,z_h,z_o =feed_forward_train(X_train,w_h,w_o,b_h,b_o,lexyRelu,Identity)\n",
    "            MSEdeglisttest[i] =MSE(y_test,y_pred_test)\n",
    "            MSEdeglisttrain[i]= MSE(y_train,y_pred_train)\n",
    "            R2deglisttest[i] = R2(y_test,y_pred_test)\n",
    "            R2deglisttrain[i] = R2(y_train,y_pred_train)\n",
    "        MSE_train_ler[counter_eta,counter_hidden] = np.mean(MSEdeglisttrain)\n",
    "        MSE_test_ler[counter_eta,counter_hidden] = np.mean(MSEdeglisttest)\n",
    "        R2_test_ler[counter_eta,counter_hidden] = np.mean(R2deglisttest)\n",
    "        R2_train_ler[counter_eta,counter_hidden] = np.mean(R2deglisttrain)\n",
    "        counter_eta +=1\n",
    "        print(counter_eta)\n",
    "    counter_hidden +=1\n",
    "    counter_eta =0\n",
    "\n",
    "tick = ticker.ScalarFormatter(useOffset=False, useMathText=True)\n",
    "tick.set_powerlimits((0,0))\n",
    "\n",
    "tx = [u\"${}$\".format(tick.format_data(x)) for x in hyper_par]\n",
    "ty = [u\"${}$\".format(tick.format_data(x)) for x in etas]\n",
    "\n",
    "#lambdas_sea = [lambdas[i] for i in range(len(lambdas))]\n",
    "#etas_sea =  [etas[i] for i in range(len(etas))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(data=MSE_test_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "ax.set_ylabel(r'$\\eta$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Test_MSE_Single_hidden_function_of_hyper_RELU.pdf\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(data=R2_test_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "ax.set_ylabel(r'$\\eta$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Test_R2_Single_hidden_function_of_hyper_RELU.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(data=MSE_train_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "ax.set_ylabel(r'$\\eta$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Train_MSE_Single_hidden_function_of_hyper_RELU.pdf\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(data=R2_train_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "ax.set_ylabel(r'$\\eta$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Train_R2_Single_hidden_function_of_hyper_RELU.pdf\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden: 1\n",
      "eta: 1e-06\n",
      "eta: 1e-05\n",
      "eta: 0.0001\n",
      "eta: 0.001\n",
      "eta: 0.01\n",
      "eta: 0.1\n",
      "Hidden: 2\n",
      "eta: 1e-06\n",
      "eta: 1e-05\n",
      "eta: 0.0001\n",
      "eta: 0.001\n",
      "eta: 0.01\n",
      "eta: 0.1\n",
      "Hidden: 4\n",
      "eta: 1e-06\n",
      "eta: 1e-05\n",
      "eta: 0.0001\n",
      "eta: 0.001\n",
      "eta: 0.01\n",
      "eta: 0.1\n",
      "Hidden: 8\n",
      "eta: 1e-06\n",
      "eta: 1e-05\n",
      "eta: 0.0001\n",
      "eta: 0.001\n",
      "eta: 0.01\n",
      "eta: 0.1\n",
      "Hidden: 16\n",
      "eta: 1e-06\n",
      "eta: 1e-05\n",
      "eta: 0.0001\n",
      "eta: 0.001\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,cancer.target.reshape(-1,1),random_state=1)\n",
    "scaler =StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "numberMinibach = np.array([4,8,16,32,64])\n",
    "numEpochs = np.array([10,100,1000])\n",
    "#epoch_index, minibach_index = 0,3 \n",
    "etas = np.logspace(-3,-1,3)\n",
    "lambdas = np.logspace(-4,0,5)\n",
    "numberOfStraps = 100\n",
    "hyper_par = np.logspace(-6,-1,6) \n",
    "#hyper = 0\n",
    "\n",
    "epochs = 100 #numEpochs[1]\n",
    "Minibach = numberMinibach[1] \n",
    "#n_hiden = np.array([1,2,4,8,16])\n",
    "#hiden = 8\n",
    "#MiniBachSize = 8\n",
    "MiniBachSice = int(X_train.shape[0]/Minibach)\n",
    "hyper =0# 0.001\n",
    "etas = np.logspace(-6,-1,6)\n",
    "hyper_par = np.logspace(-6,-1,6)\n",
    "n_hidden = np.array([1,2,4,8,16,32,64,128])\n",
    "#eta =0.01\n",
    "\n",
    "numberOfStraps = 50\n",
    "\n",
    "\n",
    "activation = Sigmoid\n",
    "out_func = Sigmoid\n",
    "\n",
    "Accuracy_test_ler = np.zeros((len(etas),len(n_hidden)))\n",
    "Accuracy_train_ler = np.zeros((len(etas),len(n_hidden)))\n",
    "\n",
    "counter_eta,counter_hidden = 0,0\n",
    "for hidden in n_hidden:\n",
    "    print('Hidden:',hidden)\n",
    "    for eta in etas:\n",
    "        print('eta:',eta)\n",
    "        Accuracydeglisttest = np.zeros(numberOfStraps)\n",
    "        Accuracydeglisttrain = np.zeros(numberOfStraps)\n",
    "        for j in range(numberOfStraps):\n",
    "            w_h,w_o,b_h,b_o =Set_weights_and_bias(30,hidden,1)\n",
    "            bootX,booty = resample(X_train,y_train)\n",
    "            for e in range(epochs):\n",
    "                for j in range(Minibach):\n",
    "                    miniBach = np.random.randint(Minibach)\n",
    "                    miniBachMin, miniBachMax = MiniBachSize * miniBach,(MiniBachSize) * (miniBach+1)\n",
    "                    #a_h,a_o = feed_forward_train(bootX[miniBachMin: miniBachMax],w_h,w_o,b_h,b_o,Sigmoid,Identity)\n",
    "                    w_out_grad,w_hidden_grad,b_out_grad, b_hidden_grad = back_prop(\n",
    "                        bootX[miniBachMin: miniBachMax],booty[miniBachMin: miniBachMax],w_h, w_o, b_h, b_o,activation, out_func,hyper,CostFunctionClassification)\n",
    "                    w_h -= eta*w_hidden_grad\n",
    "                    w_o -= eta*w_out_grad\n",
    "                    b_h -= eta*b_hidden_grad\n",
    "                    b_o -= eta*b_out_grad\n",
    "            a_h, y_pred_test,z_h,z_o =feed_forward_train(X_test,w_h,w_o,b_h,b_o,activation,out_func)\n",
    "            a_h, y_pred_train,z_h,z_o =feed_forward_train(X_train,w_h,w_o,b_h,b_o,activation,out_func)\n",
    "            Accuracydeglisttrain[j] = Accuracy(y_pred_train,y_train)\n",
    "            Accuracydeglisttest[j] = Accuracy(y_pred_test,y_test)\n",
    "        Accuracy_train_ler[counter_eta,counter_hidden] = np.mean(Accuracydeglisttrain)\n",
    "        Accuracy_test_ler[counter_eta,counter_hidden] = np.mean(Accuracydeglisttest)\n",
    "        counter_eta +=1\n",
    "    counter_hidden +=1\n",
    "    counter_eta = 0\n",
    "\n",
    "\n",
    "tick = ticker.ScalarFormatter(useOffset=False, useMathText=True)\n",
    "tick.set_powerlimits((0,0))\n",
    "\n",
    "tx = [u\"${}$\".format(tick.format_data(x)) for x in n_hidden]\n",
    "ty = [u\"${}$\".format(tick.format_data(x)) for x in etas]\n",
    "\n",
    "#lambdas_sea = [lambdas[i] for i in range(len(lambdas))]\n",
    "#etas_sea =  [etas[i] for i in range(len(etas))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(data=Accuracy_test_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "ax.set_ylabel(r'$\\eta$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Test_Accuracy_Single_hidden_function_of_hidden_Sigmoid.pdf\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(data=Accuracy_train_ler,ax=ax, cmap=\"viridis\",annot=True ,xticklabels=tx, yticklabels=ty,)\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "ax.set_ylabel(r'$\\eta$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Train_Accuracy_Single_hidden_function_of_hidden_Sigmoid.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
